#!/usr/bin/env node

/**
 * JTL-Artikel Import Fortsetzungs-Skript
 * 
 * F√ºhrt den Import in Batches fort bis alle Artikel importiert sind
 * Mit automatischem Retry bei Fehlern
 */

const BASE_URL = process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3000'
const MAX_RETRIES = 3
const RETRY_DELAY = 5000

async function continueImport() {
  console.log('üîÑ JTL-Artikel Import wird fortgesetzt...\n')
  
  // Aktuellen Status abrufen
  const statusResponse = await fetch(`${BASE_URL}/api/jtl/articles/import/status`)
  const statusData = await statusResponse.json()
  const currentCount = statusData.imported || 0
  
  console.log(`üìä Aktuell importiert: ${currentCount} Artikel`)
  console.log(`üéØ Ziel: Alle aktiven Artikel ohne St√ºckliste (~166.854)\n`)
  
  let offset = currentCount // Start ab aktuellem Stand
  let totalImported = 0
  let batchCount = 0
  const batchSize = 5000 // Gr√∂√üere Batches f√ºr schnelleren Import
  let consecutiveErrors = 0
  const MAX_CONSECUTIVE_ERRORS = 5
  
  while (true) {
    batchCount++
    console.log(`\nüì¶ Batch ${batchCount}: Importiere ab Offset ${offset}...`)
    
    let retryCount = 0
    let success = false
    
    // Retry-Loop f√ºr diesen Batch
    while (retryCount < MAX_RETRIES && !success) {
      try {
        const response = await fetch(`${BASE_URL}/api/jtl/articles/import/start`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            batchSize,
            offset,
            fullImport: false
          }),
          signal: AbortSignal.timeout(120000) // 2 Minuten Timeout
        })
        
        const data = await response.json()
        
        if (!data.ok) {
          console.error('‚ùå API-Fehler:', data.error)
          retryCount++
          if (retryCount < MAX_RETRIES) {
            console.log(`‚è≥ Retry ${retryCount}/${MAX_RETRIES} in ${RETRY_DELAY/1000}s...`)
            await new Promise(resolve => setTimeout(resolve, RETRY_DELAY))
          }
          continue
        }
        
        totalImported += data.imported
        console.log(`‚úÖ ${data.imported} Artikel importiert (Gesamt: ${data.total})`)
        
        if (data.finished || data.imported === 0) {
          console.log(`\nüéâ Import abgeschlossen!`)
          console.log(`üìä Insgesamt ${data.total} Artikel importiert`)
          return
        }
        
        offset = data.nextOffset
        consecutiveErrors = 0 // Reset Fehlerz√§hler
        success = true
        
        // Kurze Pause zwischen Batches
        await new Promise(resolve => setTimeout(resolve, 2000))
        
      } catch (error) {
        retryCount++
        consecutiveErrors++
        console.error(`‚ùå Fehler (${retryCount}/${MAX_RETRIES}):`, error.message)
        
        if (consecutiveErrors >= MAX_CONSECUTIVE_ERRORS) {
          console.error(`\nüõë Zu viele aufeinanderfolgende Fehler (${MAX_CONSECUTIVE_ERRORS}). Import abgebrochen.`)
          return
        }
        
        if (retryCount < MAX_RETRIES) {
          console.log(`‚è≥ Retry ${retryCount}/${MAX_RETRIES} in ${RETRY_DELAY/1000}s...`)
          await new Promise(resolve => setTimeout(resolve, RETRY_DELAY))
        }
      }
    }
    
    if (!success) {
      console.error(`\n‚ùå Batch ${batchCount} fehlgeschlagen nach ${MAX_RETRIES} Versuchen.`)
      console.log(`üíæ Import pausiert bei Offset ${offset}. Neustart m√∂glich.`)
      return
    }
  }
}

continueImport().catch(console.error)
